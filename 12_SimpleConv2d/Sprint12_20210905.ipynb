{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I17rg4QtwK54"
   },
   "source": [
    "# Sprint12　畳込みニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(12000, 28, 28)\n",
      "(60000,)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "# データ読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# onehotベクトル化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 訓練データと評価データに\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習に使用するその他クラスの定義\n",
    "\n",
    "これまでのsprintで定義してきたものを流用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "duKjHNocwK6C"
   },
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    Fully connected layers from number of nodes n_nodes1 to n_nodes2\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      Number of nodes in the previous layer\n",
    "    n_nodes2 : int\n",
    "      Number of nodes in subsequent layers\n",
    "    initializer : Instances of initialization methods\n",
    "    optimizer : Instances of optimization methods\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, activation):\n",
    "        \n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        # Initialize.\n",
    "        # Use the initializer method to initialize self.W and self.B\n",
    "        self.W = self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of the following form, shape (batch_size, n_nodes1)\n",
    "            Input\n",
    "        Returns\n",
    "        ----------\n",
    "        A : ndarray of the following form, shape (batch_size, n_nodes2)\n",
    "            Output\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.A = np.dot(self.X,self.W) + self.B\n",
    "        \n",
    "        return self.activation.forward(self.A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        Backward\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : ndarray of the following form, shape (batch_size, n_nodes2)\n",
    "            The gradient flowed in from behind.\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : ndarray of the following form, shape (batch_size, n_nodes1)\n",
    "            forward slope\n",
    "        \"\"\"\n",
    "        dA = self.activation.backward(dZ)\n",
    "        self.dB = np.mean(dA,axis=0)\n",
    "        self.dW = np.dot(self.X.T,dA)/len(self.X)\n",
    "        dZ = np.dot(dA,self.W.T)\n",
    "        \n",
    "        # Update\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    Simple initialization with Gaussian distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Standard deviation of Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        Initializing weights\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          Number of nodes in the previous layer\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : weight\n",
    "        \"\"\"\n",
    "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : bias\n",
    "        \"\"\"\n",
    "        return np.zeros(n_nodes2)\n",
    "    \n",
    "class HeInitializer():\n",
    "    \"\"\"\n",
    "    Initialization of weights by He\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        Initializing weights\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          Number of nodes in the previous layer\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : weight\n",
    "        \"\"\"\n",
    "        return np.random.randn(n_nodes1, n_nodes2)*np.sqrt(2/n_nodes1)\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : bias\n",
    "        \"\"\"\n",
    "        return np.zeros(n_nodes2)\n",
    "    \n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    stochastic gradient descent method\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : learning rate\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        Updating the weights and biases of a layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : An instance of the layer before the update\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr*layer.dW\n",
    "        layer.B -= self.lr*layer.dB\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    stochastic gradient descent method\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : learning rate\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.hW = 0\n",
    "        self.hB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        Updating the weights and biases of a layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : An instance of the layer before the update\n",
    "        \"\"\"\n",
    "        self.hW += layer.dW*layer.dW\n",
    "        self.hB = layer.dB*layer.dB\n",
    "    \n",
    "        layer.W -= self.lr*layer.dW/(np.sqrt(self.hW) +1e-7)\n",
    "        layer.B -= self.lr*layer.dB/(np.sqrt(self.hB) +1e-7)\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "class ReLU():\n",
    "    \"\"\"\n",
    "    Activation function : ReLU function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,A):\n",
    "        self.A = A\n",
    "        return np.maximum(self.A,0)\n",
    "    \n",
    "    def backward(self,dZ):\n",
    "        \n",
    "        return np.where(self.A>0,dZ,0)\n",
    "    \n",
    "class Softmax():\n",
    "    \"\"\"\n",
    "    Activation Function : Softmax Function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,A):\n",
    "        \n",
    "        return np.exp(A-np.max(A))/np.sum(np.exp(A-np.max(A)),axis=1,keepdims=True)\n",
    "    \n",
    "    def backward(self,dZ):\n",
    "        return dZ\n",
    "    \n",
    "# Mini-batch processing class\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    Iterator to get the mini-batch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of the following form, shape (n_samples, n_features)\n",
    "      Training data\n",
    "    y : ndarray of the following form, shape (n_samples, 1)\n",
    "      correct value\n",
    "    batch_size : int\n",
    "      Batch size\n",
    "    seed : int\n",
    "      Seeding random numbers in NumPy\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=None):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1] \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmW0YtuQwK6C"
   },
   "source": [
    "# 畳み込み層の重みとバイアスの初期化クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uD3iuDwMwK6D"
   },
   "outputs": [],
   "source": [
    "class SimpleInitializerConv2d:\n",
    "    \"\"\"重みとバイアスの初期化（畳込み用）\"\"\"\n",
    "    def __init__(self, sigma=0.01):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        --------------\n",
    "        sigma : ガウス分布の標準偏差\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, F, C, FH, FW):\n",
    "        \"\"\"重み初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        F : フィルタ数\n",
    "        C : チャンネル数\n",
    "        FH : フィルターの高さ\n",
    "        FW : フィルターの横幅\n",
    "        \"\"\"\n",
    "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
    "    \n",
    "    def B(self, F):\n",
    "        \"\"\"バイアス初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        F : フィルタ数\n",
    "        \"\"\"\n",
    "        return np.zeros(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2fxdDrkwK6F"
   },
   "source": [
    "# 問題1　2次元畳み込み層の作成\n",
    "\n",
    "https://qiita.com/eijian/items/c947fb6b5e7a49858fb4#2-3-%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E5%B1%A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WGQfEoYwK6G"
   },
   "source": [
    "$$a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9q7iydz8wK6H"
   },
   "outputs": [],
   "source": [
    "class SimpleConv2d():\n",
    "    \"\"\"2次元畳み込みレイヤ\"\"\"\n",
    "    def __init__(self, F, C, FH, FW, P, S,\n",
    "                 initializer=None,optimizer=None,activation=None):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        -------------\n",
    "        F : フィルタ数\n",
    "        C : チャンネル数\n",
    "        FH : フィルターの高さ\n",
    "        FW : フィルターの横幅\n",
    "        P : パディング数\n",
    "        S : ストライド数\n",
    "        initializer : 初期化\n",
    "        optimizer : 最適化手法\n",
    "        activation : 活性化関数\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        self.S = S\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        # 重みとバイアスの初期化\n",
    "        self.W = self.initializer.W(F,C,FH,FW)\n",
    "        self.B = self.initializer.B(F)\n",
    "        \n",
    "    def output_shape2d(self,H,W,PH,PW,FH,FW,SH,SW):\n",
    "        \"\"\"出力サイズ計算\n",
    "        H : 入力配列の高さ\n",
    "        W : 入力配列の横幅\n",
    "        FH : フィルターの高さ\n",
    "        FW : フィルターの横幅\n",
    "        PH : パディング数（縦）\n",
    "        PW : パディング数（横）\n",
    "        SH : ストライド数（縦）\n",
    "        SW : ストライド数（横）\n",
    "        \"\"\"\n",
    "        # 高さ計算\n",
    "        OH = (H +2*PH -FH)/SH +1\n",
    "        # 横幅計算\n",
    "        OW = (W +2*PW -FW)/SW +1\n",
    "        \n",
    "        return int(OH),int(OW)\n",
    "    \n",
    "    def forward(self, X,debug=False):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ------------\n",
    "        X : 入力配列\n",
    "        \"\"\"\n",
    "        # Xをメンバ変数化\n",
    "        self.X = X\n",
    "        # 入力配列と重みの大きさ取得\n",
    "        N,C,H,W = self.X.shape\n",
    "        F,C,FH,FW = self.W.shape\n",
    "        # 出力サイズ計算\n",
    "        OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
    "        # 各種サイズをメンバ変数化\n",
    "        self.params = N,C,H,W,F,FH,FW,OH,OW\n",
    "        # 返り値の初期化（これを上書きしていく）\n",
    "        A = np.zeros([N,F,OH,OW])\n",
    "        # 計算のためパディング処理\n",
    "        self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
    "\n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 高さでループ（ストライドを考慮）\n",
    "                for row in range(0,H,self.S):\n",
    "                    # 横幅でループ（ストライドを考慮）\n",
    "                    for col in range(0,W,self.S):\n",
    "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
    "                            continue\n",
    "                        # 各要素計算\n",
    "                        A[n,ch,row,col] = \\\n",
    "                        np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]\n",
    "                               *self.W[ch,:,:,:]) +self.B[ch]\n",
    "        # 活性化関数に通して返す\n",
    "        if debug==True:\n",
    "            return A\n",
    "        else:\n",
    "            return  self.activation.forward(A)\n",
    "    \n",
    "    def backward(self, dZ,debug=False):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        -----------\n",
    "        dZ : 逆伝播してきた値\n",
    "        \"\"\"\n",
    "        # 活性化関数の逆伝播処理\n",
    "        if debug==True:\n",
    "            dA = dZ\n",
    "        else:\n",
    "            dA = self.activation.backward(dZ)\n",
    "        # 順伝播の際にメンバ変数化しておいた各種サイズを取得\n",
    "        N,C,H,W,F,FH,FW,OH,OW = self.params\n",
    "        # 返り値と重みとバイアスの初期化（これを上書きしていく）\n",
    "        dZ = np.zeros(self.X_pad.shape) # X_padのサイズで初期化していることに注意\n",
    "        self.dW = np.zeros(self.W.shape)\n",
    "        self.dB = np.zeros(self.B.shape)\n",
    "        \n",
    "        # dZ（逆伝播）\n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 高さでループ（ストライドを考慮）\n",
    "                for row in range(0,H,self.S):\n",
    "                    # 横幅でループ（ストライドを考慮）\n",
    "                    for col in range(0,W,self.S):\n",
    "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
    "                            continue\n",
    "                        # 各要素計算\n",
    "                        dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
    "        \n",
    "        # X_padのサイズになっているので、不要な部分を削除\n",
    "        if self.P == 0:\n",
    "            dZ = np.delete(dZ,[0,H-1],axis=2)\n",
    "            dZ = np.delete(dZ,[0,W-1],axis=3)\n",
    "        else:\n",
    "            dl_rows = range(self.P),range(H+self.P,H+2*self.P,1)\n",
    "            dl_cols = range(self.P),range(W+self.P,W+2*self.P,1)\n",
    "            dZ = np.delete(dZ,dl_rows,axis=2)\n",
    "            dZ = np.delete(dZ,dl_cols,axis=3)\n",
    " \n",
    "        # dW（重み）\n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 高さでループ\n",
    "                for row in range(OH):\n",
    "                    # 横幅でループ\n",
    "                    for col in range(OW):\n",
    "                        # 各要素計算\n",
    "                        self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
    "        \n",
    "        # dB（バイアス）\n",
    "        # フィルター数でループ\n",
    "        for ch in range(F):\n",
    "            self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
    "        \n",
    "        # 重み更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題2　小さな配列での2次元畳み込み層の実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-4. -4.]\n",
      "   [-4. -4.]]\n",
      "\n",
      "  [[ 1.  1.]\n",
      "   [ 1.  1.]]]]\n",
      "[[[[-5.  4.]\n",
      "   [13. 27.]]]]\n"
     ]
    }
   ],
   "source": [
    "# データの定義\n",
    "x = np.array([[[[ 1,  2,  3,  4],[ 5,  6,  7,  8],[ 9, 10, 11, 12],[13, 14, 15, 16]]]])\n",
    "w = np.array([[[[ 0.,  0.,  0.],[ 0.,  1.,  0.],[ 0., -1.,  0.]]],[[[ 0.,  0.,  0.],[ 0., -1.,  1.],[ 0.,  0.,  0.]]]])\n",
    "da = np.array([[[[ -4,  -4], [ 10,  11]],[[  1,  -7],[  1, -11]]]])\n",
    "\n",
    "# インスタンス定義と重み上書き\n",
    "simple_conv_2d = SimpleConv2d(F=2, C=1, FH=3, FW=3, P=0, S=1,initializer=SimpleInitializerConv2d(),optimizer=SGD(),activation=ReLU())\n",
    "simple_conv_2d.W = w\n",
    "\n",
    "# 順伝播\n",
    "A = simple_conv_2d.forward(x,True)\n",
    "print(A)\n",
    "\n",
    "# 逆伝播\n",
    "dZ = simple_conv_2d.backward(da,True)\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnistを使ったテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 28, 28)\n",
      "(5, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# ストライド/パディング/バッチ数の定義\n",
    "S = 1\n",
    "P = 1\n",
    "N = 5 \n",
    "\n",
    "# 入力配列と重みのサイズ定義\n",
    "N,C,H,W = (5,1,28,28)\n",
    "F,C,FH,FW = (4,1,3,3)\n",
    "\n",
    "# X（入力配列生成）\n",
    "X_sample = X_train[0:N].reshape(N,C,H,W)\n",
    "\n",
    "# インスタンス生成\n",
    "simple_conv_2d = SimpleConv2d(F=F, C=C, FH=FH, FW=FW, P=P, S=S,initializer=SimpleInitializerConv2d(),optimizer=SGD(),activation=ReLU())\n",
    "\n",
    "# 順伝播\n",
    "A = simple_conv_2d.forward(X_sample)\n",
    "print(A.shape)\n",
    "\n",
    "# 逆伝播\n",
    "dA = np.ones(A.shape)\n",
    "dZ = simple_conv_2d.backward(X_sample)\n",
    "print(dZ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Hwp3fknwK6H"
   },
   "source": [
    "# 問題3　2次元畳み込み後の出力サイズ\n",
    "\n",
    "問題2のクラス内で定義済み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3_fksagCwK6I",
    "outputId": "63ff990b-c074-4ee5-e55f-441fcfd08b1e",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_conv_2d.output_shape2d(H=6,W=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VkJ-KlgwK6J"
   },
   "source": [
    "# 問題4　最大プーリング層の作成\n",
    "\n",
    "https://qiita.com/eijian/items/c947fb6b5e7a49858fb4#2-2-%E3%83%97%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0%E5%B1%A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ViTwMwPvwK6J"
   },
   "outputs": [],
   "source": [
    "class MaxPool2D():\n",
    "    \"\"\"最大プーリング層\n",
    "    \"\"\"\n",
    "    def __init__(self,P):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        -----------\n",
    "        P : プーリング幅\n",
    "        \"\"\"\n",
    "        self.P = P\n",
    "        # 順伝播の返り値\n",
    "        self.PA = None\n",
    "        # 最大値のインデックス記録\n",
    "        self.Pindex = None\n",
    "        \n",
    "    def forward(self,A):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        -----------\n",
    "        A : 入力配列\n",
    "        \"\"\"\n",
    "        # 入力配列のサイズ\n",
    "        N,F,OH,OW = A.shape\n",
    "        # \n",
    "        PS = self.P\n",
    "        # 縦軸と横軸のスライド回数\n",
    "        PH,PW = int(OH/PS),int(OW/PS)\n",
    "        \n",
    "        # 各種パラメータの保存\n",
    "        self.params = N,F,OH,OW,PS,PH,PW\n",
    "        \n",
    "        # プーリング処理のための初期化\n",
    "        self.PA = np.zeros([N,F,PH,PW])\n",
    "        self.Pindex = np.zeros([N,F,PH,PW])\n",
    "        \n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 縦方向スライド回数\n",
    "                for row in range(PH):\n",
    "                    # 横方向スライド回数\n",
    "                    for col in range(PW):\n",
    "                        # 順伝播の値計算\n",
    "                        self.PA[n,ch,row,col] = \\\n",
    "                        np.max(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
    "                        # 最大値のインデックス記録\n",
    "                        self.Pindex[n,ch,row,col] = \\\n",
    "                        np.argmax(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
    "                        \n",
    "        return self.PA\n",
    "    \n",
    "    def backward(self,dA):\n",
    "        \"\"\"逆伝播の値\n",
    "        Parameters\n",
    "        -----------\n",
    "        dA : 逆伝播してきた値\n",
    "        \"\"\"\n",
    "        # 保存しておいた各種パラメータ取得\n",
    "        N,F,OH,OW,PS,PH,PW = self.params\n",
    "        # 逆伝播の値\n",
    "        dP = np.zeros([N,F,OH,OW])\n",
    "        # バッチ数でループ\n",
    "        for n in range(N):\n",
    "            # フィルター数でループ\n",
    "            for ch in range(F):\n",
    "                # 縦方向スライド回数\n",
    "                for row in range(PH):\n",
    "                    # 横方向スライド回数\n",
    "                    for col in range(PW):\n",
    "                        # 最大値を取得してきたインデックスの取得\n",
    "                        idx = self.Pindex[n,ch,row,col]\n",
    "                        # 逆伝播の一時保存変数\n",
    "                        tmp = np.zeros((PS*PS))\n",
    "                        for i in range(PS*PS):\n",
    "                            # 該当インデックスはその値\n",
    "                            if i == idx:\n",
    "                                tmp[i] = dA[n,ch,row,col]\n",
    "                            # それ以外は0\n",
    "                            else:\n",
    "                                tmp[i] = 0\n",
    "                        # 返り値の該当場所に格納\n",
    "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
    "        \n",
    "        return dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_K85cvI6wK6J",
    "outputId": "9725b784-ad28-44a2-8be3-aa1fe3688e87",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------X\n",
      "[[[[3 3 6 2 6 7]\n",
      "   [7 3 3 7 7 7]\n",
      "   [6 3 3 6 4 0]\n",
      "   [4 8 3 1 5 5]\n",
      "   [1 6 0 0 5 7]\n",
      "   [4 1 8 3 3 6]]]]\n",
      "---------------A\n",
      "[[[[7. 7. 7.]\n",
      "   [8. 6. 5.]\n",
      "   [6. 8. 7.]]]]\n",
      "---------------dA\n",
      "[[[[1 1 8]\n",
      "   [6 1 2]\n",
      "   [7 2 3]]]]\n",
      "---------------dZ\n",
      "[[[[0. 0. 0. 0. 0. 8.]\n",
      "   [1. 0. 0. 1. 0. 0.]\n",
      "   [0. 0. 0. 1. 0. 0.]\n",
      "   [0. 6. 0. 0. 2. 0.]\n",
      "   [0. 7. 0. 0. 0. 3.]\n",
      "   [0. 0. 2. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "# データ準備\n",
    "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
    "print(\"---------------X\")\n",
    "print(X)\n",
    "\n",
    "# インスタンス生成と順伝播\n",
    "Pooling = MaxPool2D(P=2)\n",
    "A = Pooling.forward(X)\n",
    "print(\"---------------A\")\n",
    "print(A)\n",
    "\n",
    "# 逆伝播してきた配列定義\n",
    "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
    "print(\"---------------dA\")\n",
    "print(dA)\n",
    "\n",
    "# 逆伝播\n",
    "dZ = Pooling.backward(dA)\n",
    "print(\"---------------dZ\")\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdMUr2VLwK6M"
   },
   "source": [
    "# 問題6　平滑化\n",
    "\n",
    "最終的な出力を1次元配列とするため、平滑化レイヤーを作成する。\n",
    "\n",
    "why:分類にしろ回帰にしろ、2次元のままじゃ扱えない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CGFt2uxFwK6M"
   },
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \"\"\"平滑化レイヤー\"\"\"\n",
    "    def __ini__(self):\n",
    "        \"\"\"コンストラクタ\"\"\"\n",
    "        pass\n",
    "    def forward(self,X):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : 入力配列\n",
    "        \"\"\"\n",
    "        self.shape = X.shape\n",
    "        return X.reshape(len(X),-1)\n",
    "\n",
    "    def backward(self,X):\n",
    "        \"\"\"逆伝播の値\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : 逆伝播してきた値\n",
    "        \"\"\"\n",
    "        return X.reshape(self.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0uJcS2MHwK6M",
    "outputId": "32f159e4-54ac-4100-f256-57f97724f422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward_shape: (20, 50)\n",
      "Backward_shape: (20, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "# データ準備\n",
    "TEST = np.zeros([20,2,5,5])\n",
    "\n",
    "# インスタンス生成\n",
    "flt = Flatten()\n",
    "\n",
    "# 順伝播\n",
    "flat_forward = flt.forward(TEST)\n",
    "\n",
    "# 逆伝播\n",
    "flat_back = flt.backward(flat_forward)\n",
    "\n",
    "print('Forward_shape:',flat_forward.shape)\n",
    "print('Backward_shape:',flat_back.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fux5jvxuwK6N"
   },
   "source": [
    "# 問題7　学習と推定\n",
    "\n",
    "CNNクラスを定義し、それを基に学習と推定を行っていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hnkAOmCEwK6N"
   },
   "outputs": [],
   "source": [
    "# Scratch CNN\n",
    "class Scratch2dCNNClassifier():\n",
    "    \"\"\"CNNスクラッチ\n",
    "    \"\"\"\n",
    "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose = False):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        -----------\n",
    "        NN : 辞書型でレイヤーのインスタンスを格納\n",
    "        CNN : 辞書型でレイヤーのインスタンスを格納\n",
    "        n_epoch : 学習回数\n",
    "        n_batch : バッチ数\n",
    "        verbose : ログ出力するか否か\n",
    "        \"\"\"\n",
    "        self.NN = NN\n",
    "        self.CNN = CNN\n",
    "        self.n_epoch = n_epoch\n",
    "        self.n_batch = n_batch\n",
    "        self.verbose = verbose\n",
    "        # ログ記録用\n",
    "        self.log_loss = np.zeros(self.n_epoch)\n",
    "        self.log_acc = np.zeros(self.n_epoch)\n",
    "        \n",
    "        \n",
    "    def loss_function(self,y,yt):\n",
    "        \"\"\"クロスエントロピー誤差\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 予測値\n",
    "        yt : 正解データ\n",
    "        \"\"\"\n",
    "        delta = 1e-7\n",
    "        return -np.mean(yt*np.log(y+delta))\n",
    "    \n",
    "    def accuracy(self,Z,Y):\n",
    "        \"\"\"クロスエントロピー誤差\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 予測値\n",
    "        Y : 正解データ\n",
    "        \"\"\"\n",
    "        return accuracy_score(Y,Z)\n",
    "                \n",
    "    def fit(self, X, y, X_val=False, y_val=False):\n",
    "        \"\"\"学習\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 訓練データの説明変数\n",
    "        y : 訓練データの目的変数\n",
    "        X_val : 評価データの説明変数\n",
    "        y_val : 評価データの目的変数\n",
    "        \"\"\"\n",
    "        # 学習回数分ループ\n",
    "        for epoch in range(self.n_epoch):\n",
    "            # ミニバッチイテレータ生成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
    "            # バッチの合計損失格納\n",
    "            self.loss = 0\n",
    "            # ミニバッチイテレータでループ\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:              \n",
    "                ############### 順伝播\n",
    "                # データ準備\n",
    "                forward_data = mini_X_train[:,np.newaxis,:,:]\n",
    "                # 畳込み\n",
    "                for layer in range(len(self.CNN)):\n",
    "                    forward_data = self.CNN[layer].forward(forward_data)\n",
    "                # 平滑化\n",
    "                flt = Flatten()\n",
    "                forward_data = flt.forward(forward_data)\n",
    "                # 通常のNN\n",
    "                for layer in range(len(self.NN)):\n",
    "                    forward_data = self.NN[layer].forward(forward_data)\n",
    "                    \n",
    "                ############### 逆伝播\n",
    "                # データ準備\n",
    "                Z = forward_data\n",
    "                backward_data = (Z - mini_y_train)/self.n_batch\n",
    "                # 通常のNN\n",
    "                for layer in range(len(self.NN)-1,-1,-1):\n",
    "                    backward_data = self.NN[layer].backward(backward_data)\n",
    "                # 平滑化\n",
    "                backward_data = flt.backward(backward_data)\n",
    "                # 畳み込み\n",
    "                for layer in range(len(self.CNN)-1,-1,-1):\n",
    "                    backward_data = self.CNN[layer].backward(backward_data)\n",
    "                \n",
    "                # 損失計算\n",
    "                self.loss += self.loss_function(Z,mini_y_train)\n",
    "                if self.verbose:\n",
    "                    print('batch loss %f'%self.loss_function(Z,mini_y_train))\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(self.loss/len(get_mini_batch),self.accuracy(self.predict(X),np.argmax(y,axis=1)))\n",
    "            # 損失記録用\n",
    "            self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
    "            self.log_acc[epoch] = self.accuracy(self.predict(X),np.argmax(y,axis=1))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"予測\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        \"\"\"\n",
    "        # データ準備\n",
    "        pred_data = X[:,np.newaxis,:,:]\n",
    "        \n",
    "        # 畳込み\n",
    "        for layer in range(len(self.CNN)):\n",
    "            pred_data = self.CNN[layer].forward(pred_data)\n",
    "        # 平滑化\n",
    "        pred_data = flt.forward(pred_data)\n",
    "        # 通常のNN\n",
    "        for layer in range(len(self.NN)):\n",
    "            pred_data = self.NN[layer].forward(pred_data)\n",
    "        # 最も大きい値のインデックスを採用\n",
    "        return np.argmax(pred_data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Nd2itkg0wK6N"
   },
   "outputs": [],
   "source": [
    "# レイヤー群定義\n",
    "NN = {\n",
    "    0:FC(1960, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
    "    1:FC(200, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
    "    2:FC(200, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),\n",
    "}\n",
    "\n",
    "CNN = {\n",
    "    0:SimpleConv2d(\n",
    "        F=10, C=1, FH=3, FW=3, P=1, S=1,\n",
    "        initializer=SimpleInitializerConv2d(),\n",
    "        optimizer=SGD(),\n",
    "        activation=ReLU()),\n",
    "    1:MaxPool2D(2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "at4_QFo8wK6O"
   },
   "outputs": [],
   "source": [
    "# CNNクラスのインスタンス化\n",
    "cnn1 = Scratch2dCNNClassifier(NN=NN,CNN=CNN,n_epoch=1,n_batch=20,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.230250\n",
      "batch loss 0.229682\n",
      "batch loss 0.233400\n",
      "batch loss 0.228415\n",
      "batch loss 0.228347\n",
      "batch loss 0.225633\n",
      "batch loss 0.228474\n",
      "batch loss 0.216597\n",
      "batch loss 0.218719\n",
      "batch loss 0.191143\n",
      "batch loss 0.209072\n",
      "batch loss 0.197775\n",
      "batch loss 0.192849\n",
      "batch loss 0.173868\n",
      "batch loss 0.139771\n",
      "batch loss 0.160175\n",
      "batch loss 0.166565\n",
      "batch loss 0.162981\n",
      "batch loss 0.130667\n",
      "batch loss 0.094744\n",
      "batch loss 0.149757\n",
      "batch loss 0.134562\n",
      "batch loss 0.125267\n",
      "batch loss 0.099205\n",
      "batch loss 0.111141\n",
      "batch loss 0.146097\n",
      "batch loss 0.117594\n",
      "batch loss 0.099532\n",
      "batch loss 0.082109\n",
      "batch loss 0.062607\n",
      "batch loss 0.094046\n",
      "batch loss 0.170494\n",
      "batch loss 0.105054\n",
      "batch loss 0.116070\n",
      "batch loss 0.080736\n",
      "batch loss 0.054969\n",
      "batch loss 0.041841\n",
      "batch loss 0.095923\n",
      "batch loss 0.096904\n",
      "batch loss 0.065358\n",
      "batch loss 0.035445\n",
      "batch loss 0.108832\n",
      "batch loss 0.074713\n",
      "batch loss 0.065241\n",
      "batch loss 0.056604\n",
      "batch loss 0.042379\n",
      "batch loss 0.069475\n",
      "batch loss 0.064493\n",
      "batch loss 0.070952\n",
      "batch loss 0.099380\n",
      "0.1319180783744724 0.751\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "cnn1.fit(X_train[0:1000],y_train_one_hot[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ou7d7r_BwK6O",
    "outputId": "ce01563d-16df-4914-a9bc-eb321c6f15b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.730\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "y_pred = cnn1.predict(X_val[0:100])\n",
    "\n",
    "# ACC算出\n",
    "accuracy = accuracy_score(np.argmax(y_val[0:100],axis=1), y_pred)\n",
    "print('accuracy:{:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9QTh7iR_wK6O",
    "outputId": "d201b5c1-80ea-402c-a760-4db5f671a5c1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線の可視化\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "fig=plt.subplots(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('LOSS')\n",
    "plt.plot(cnn1.log_loss,'bo--')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('ACC')\n",
    "plt.plot(cnn1.log_acc,'rs--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtP8R-9hwK6Q"
   },
   "source": [
    "# 問題10　出力サイズとパラメータ数の計算\n",
    "\n",
    "\n",
    "1.\n",
    "\n",
    "* 入力サイズ : 144×144, 3チャンネル\n",
    "* フィルタサイズ : 3×3, 6チャンネル\n",
    "* ストライド : 1\n",
    "* パディング : なし\n",
    "\n",
    "→ 出力サイズ：6×142×142\n",
    "\n",
    "→ パラメータ数（重み）（F×C×FH×FW）：162\n",
    "\n",
    "→ パラメータ数（バイアス）（F）：6\n",
    "\n",
    "2.\n",
    "\n",
    "* 入力サイズ : 60×60, 24チャンネル\n",
    "* フィルタサイズ : 3×3, 48チャンネル\n",
    "* ストライド　: 1\n",
    "* パディング : なし\n",
    "\n",
    "→ 出力サイズ：48×58×58\n",
    "\n",
    "→ パラメータ数（重み）（F×C×FH×FW）：10368\n",
    "\n",
    "→ パラメータ数（バイアス）（F）：48\n",
    "\n",
    "3.\n",
    "\n",
    "* 入力サイズ : 20×20, 10チャンネル\n",
    "* フィルタサイズ: 3×3, 20チャンネル\n",
    "* ストライド : 2\n",
    "* パディング : なし\n",
    "\n",
    "→ 出力サイズ：20x9x9\n",
    "\n",
    "→ パラメータ数（重み）（F×C×FH×FW）：1800\n",
    "\n",
    "→ パラメータ数（バイアス）（F）：20"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "mep_day19_CNN2_en.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "目次",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "428px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
