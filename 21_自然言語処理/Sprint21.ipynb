{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint21 自然言語処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの準備\n",
    "\n",
    "下記のURLから、圧縮ファイルをダウンロードしてください。\n",
    "\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "ダウンロードした圧縮ファイルを解凍し、このsprint21.ipynbと同じ階層においてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsRt76fLfJnt",
    "outputId": "899e2243-8177-48eb-cd70-3e42dffae5ee"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review = load_files('./aclImdb/train/', encoding='utf-8')\n",
    "x_train, y_train = train_review.data, train_review.target\n",
    "test_review = load_files('./aclImdb/test/', encoding='utf-8')\n",
    "x_test, y_test = test_review.data, test_review.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\n",
      "(25000,) (25000,) (25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "# テスト出力\n",
    "print(\"x : {}\".format(x_train[0]))\n",
    "print(np.array(x_train).shape,np.array(x_test).shape,np.array(y_train).shape,np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1　BoWのスクラッチ実装\n",
    "\n",
    "まずは、sklearnでBoWを計算してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4ZhklgU9fvsN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>bad</th>\n",
       "      <th>film</th>\n",
       "      <th>good</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>this</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  bad  film  good  is  movie  this  very\n",
       "0  0    0     0     1   1      1     1     1\n",
       "1  1    0     1     1   1      0     1     0\n",
       "2  0    2     0     0   0      0     0     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 仮のデータ\n",
    "mini_dataset = ['This movie is very good.','This film is a good','Very bad. Very, very bad.']\n",
    "\n",
    "# インスタンス化\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')\n",
    "# 実行\n",
    "bow = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "# DataFrame化\n",
    "df = pd.DataFrame(bow, columns=vectorizer.get_feature_names())\n",
    "# 出力\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvehDPWLjOf3"
   },
   "source": [
    "次に、スクラッチで作ってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>never</th>\n",
       "      <th>funny</th>\n",
       "      <th>best</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>ever</th>\n",
       "      <th>soooo</th>\n",
       "      <th>what</th>\n",
       "      <th>a</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i  never  funny  best  is  movie  ever  soooo  what  a  this\n",
       "0  0      0      1     0   1      1     0      1     0  0     1\n",
       "1  1      1      0     0   0      1     0      0     1  1     0\n",
       "2  0      0      0     1   0      2     1      0     0  0     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bow(data):\n",
    "    \"\"\"BoW算出\n",
    "    Parameters\n",
    "    -----------\n",
    "    data : 文章リスト\n",
    "    \"\"\"\n",
    "    ## 単語リスト作成\n",
    "    # 小文字に統一\n",
    "    # !除去\n",
    "    # 文字列を半角スペース基準で分割し、リスト化\n",
    "    row_data = [i.lower().replace('!', '').split(' ') for i in data]\n",
    "    # 1次元のリストに(単語リスト)\n",
    "    feature_names = set(list(itertools.chain.from_iterable(row_data)))\n",
    "    \n",
    "    ## bow計算\n",
    "    bow = []\n",
    "    # 1つづつ文章でループ\n",
    "    for index,row in enumerate(data):\n",
    "        bow.append([])\n",
    "        # 単語リストでループ\n",
    "        for feature_name in feature_names:\n",
    "            # 何個含まれているか\n",
    "            num = row_data[index].count(feature_name)\n",
    "            # 追加\n",
    "            bow[index].append(num)\n",
    "    return feature_names,bow\n",
    "\n",
    "# 仮データの定義\n",
    "mini_dataset = ['This movie is SOOOO funny!!!','What a movie! I never','best movie ever!!!!! this movie']\n",
    "# bow関数実行\n",
    "feature_names,bow = bow(mini_dataset)\n",
    "# DF化\n",
    "df = pd.DataFrame(bow, columns=feature_names)\n",
    "# 出力\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir33tt6fowT4"
   },
   "source": [
    "# 問題2　TF-IDFの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop word : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\root\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# nltkライブラリのstopwordsを利用\n",
    "stop_words = nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "print(\"stop word : {}\".format(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KzRSkeI0pqDm"
   },
   "outputs": [],
   "source": [
    "# tfidfの算出\n",
    "vectorizer = TfidfVectorizer(stop_words= stop_words, max_features=5000)\n",
    "X_train = vectorizer.fit_transform(x_train)\n",
    "X_test = vectorizer.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iq5lGtSVrLuM",
    "outputId": "d28c2fad-4da6-4d1c-bd44-677649c0dbd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000) (25000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# テスト出力\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wySgKLlLsFR-"
   },
   "source": [
    "# 問題3　TF-IDFを用いた学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XhlMa19-r5cP"
   },
   "outputs": [],
   "source": [
    "# lightGBMを用いた学習\n",
    "lgb = lgb.LGBMClassifier().fit(X_train,y_train)\n",
    "# 推定\n",
    "y_pred = lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LvsaUlNsSHf",
    "outputId": "562e89ec-4893-4f02-aae3-28e60626daff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57248\n",
      "[[6871 5629]\n",
      " [5059 7441]]\n"
     ]
    }
   ],
   "source": [
    "# 結果出力\n",
    "print(\"{}\".format(lgb.score(X_test, y_test)))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wulnj4AesQ6R"
   },
   "source": [
    "# 問題4　TF-IDFのスクラッチ実装\n",
    "\n",
    "まずは、sklearnでtfidfを計算してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仮データ\n",
    "mini_dataset = ['This movie is SOOOO funny!!!','What a movie! I never','best movie ever!!!!! this movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>funny</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>never</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.298032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.383770</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501651</td>\n",
       "      <td>0.501651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381519</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       best      ever     funny        is     movie     never     soooo  \\\n",
       "0  0.000000  0.000000  0.504611  0.504611  0.298032  0.000000  0.504611   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.385372  0.652491  0.000000   \n",
       "2  0.501651  0.501651  0.000000  0.000000  0.592567  0.000000  0.000000   \n",
       "\n",
       "       this      what  \n",
       "0  0.383770  0.000000  \n",
       "1  0.000000  0.652491  \n",
       "2  0.381519  0.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インスタンス化\n",
    "tfidf_model = TfidfVectorizer()\n",
    "# 計算\n",
    "tfidf = tfidf_model.fit_transform(mini_dataset)\n",
    "# DF化\n",
    "tfidf = pd.DataFrame(tfidf.toarray(), columns=tfidf_model.get_feature_names())\n",
    "# 出力\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、スクラッチで作ってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>funny</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>never</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.298032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.383770</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501651</td>\n",
       "      <td>0.501651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381519</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       best      ever     funny        is     movie     never     soooo  \\\n",
       "0  0.000000  0.000000  0.504611  0.504611  0.298032  0.000000  0.504611   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.385372  0.652491  0.000000   \n",
       "2  0.501651  0.501651  0.000000  0.000000  0.592567  0.000000  0.000000   \n",
       "\n",
       "       this      what  \n",
       "0  0.383770  0.000000  \n",
       "1  0.000000  0.652491  \n",
       "2  0.381519  0.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インスタンス化\n",
    "cv_model = CountVectorizer()\n",
    "# 計算\n",
    "cv= cv_model.fit_transform(mini_dataset)\n",
    "# 扱いやすいように配列化\n",
    "cv_array = cv.toarray()\n",
    "\n",
    "# TF値計算\n",
    "N = cv_array.shape[0]\n",
    "tf = np.array([cv_array[i, :] / np.sum(cv_array, axis=1)[i] for i in range(N)])\n",
    "\n",
    "# IDF値計算\n",
    "df = np.count_nonzero(cv_array, axis=0)\n",
    "idf = np.log((1 + N) / (1 + df)) + 1\n",
    "\n",
    "# normalize\n",
    "tfidf = normalize(tf*idf)\n",
    "tfidf = pd.DataFrame(tfidf, columns=cv_model.get_feature_names())\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題5　コーパスの前処理\n",
    "\n",
    "この問題以降は簡単のため、1文のみを扱う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----before processing\n",
      "I don't hand out \"ones\" often, but if there was ever a film that deserved this sort of attention, it's \"Gas!\" This is self-indulgent crap that reaches for some of the ambiance of M*A*S*H and falls completely flat on its face in the attempt.<br /><br />I see what Corman was going for - Malcolm Marmorstein and Elliott Gould tried to reproduce Gould's deathless role in the original movie version of M*A*S*H with a similar plot (in the movie \"Whiffs\" - look it up here in IMDb, http://www.imdb.com/title/tt0073891/ for more information).<br /><br />Marmorstein and Gould got closer to the brass ring with \"Whiffs\" than Corman did with \"Gas!\" but didn't quite get there. Neither one of those films even got close to the success of M*A*S*H.<br /><br />What's wrong with \"Gas!\"? What isn't? No one comes close to really acting at a level above junior high school theatrics. The production values stink. Someone else here mentioned the magically regenerating headlights on a getaway car, and there's more of that lack of attention to detail. Nothing works the way it's supposed to in this film, and nobody cares.<br /><br />\"Gas!\" actually put me to sleep. It's not a sure cure for insomnia, but really close. On the Cinematic Sleep Induction scale, \"Gas!\" falls somewhere between \"Last Year at Marienbad\" and George Clooney's remake of \"Solaris\" (which itself was remarkable for being more boring than the Mosfilm original, despite that studio's seeming unfamiliarity with the idea of keeping the audience's attention by judicious editing).<br /><br />Judicious editing would have decimated \"Gas!\" to about twenty minutes. The result would be pointless, but no more so than the original film.<br /><br />Certain films are so bad that they have a compelling quality that makes them worth watching anyway. This isn't one of them. Don't waste your time. It's not even amusingly bad.\n",
      "-----after processing\n",
      "i dont hand out ones often but if there was ever a film that deserved this sort of attention its gas this is selfindulgent crap that reaches for some of the ambiance of mash and falls completely flat on its face in the attempt  i see what corman was going for  malcolm marmorstein and elliott gould tried to reproduce goulds deathless role in the original movie version of mash with a similar plot in the movie whiffs  look it up here in imdb  for more information  marmorstein and gould got closer to the brass ring with whiffs than corman did with gas but didnt quite get there neither one of those films even got close to the success of mash  whats wrong with gas what isnt no one comes close to really acting at a level above junior high school theatrics the production values stink someone else here mentioned the magically regenerating headlights on a getaway car and theres more of that lack of attention to detail nothing works the way its supposed to in this film and nobody cares  gas actually put me to sleep its not a sure cure for insomnia but really close on the cinematic sleep induction scale gas falls somewhere between last year at marienbad and george clooneys remake of solaris which itself was remarkable for being more boring than the mosfilm original despite that studios seeming unfamiliarity with the idea of keeping the audiences attention by judicious editing  judicious editing would have decimated gas to about twenty minutes the result would be pointless but no more so than the original film  certain films are so bad that they have a compelling quality that makes them worth watching anyway this isnt one of them dont waste your time its not even amusingly bad\n"
     ]
    }
   ],
   "source": [
    "# 簡単のため、URL含んでそうな1文抜き出す\n",
    "with_url = 0\n",
    "for i, s in enumerate(x_train):\n",
    "    if 'www' in s:\n",
    "        with_url = i\n",
    "        print('-----before processing')\n",
    "        print(s)\n",
    "        break\n",
    "no_preprocessing = x_train[with_url]\n",
    "\n",
    "# urlは除外\n",
    "after_preprocessing1 = re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", no_preprocessing) \n",
    "# タグ除去\n",
    "after_preprocessing2 = re.sub(r'<[^>]+>', \" \", after_preprocessing1) \n",
    "# 数字と英字以外除去\n",
    "after_preprocessing3 = re.sub(r\"[^0-9a-zA-Z ]\", \"\", after_preprocessing2) \n",
    "# 小文字に統一\n",
    "after_preprocessing = after_preprocessing3.lower() \n",
    "\n",
    "print('-----after processing')\n",
    "print(after_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題6　Word2Vecの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語リスト\n",
    "word_list = [after_preprocessing.split(' ')]\n",
    "\n",
    "# vector_size: 圧縮次元数\n",
    "# min_count: 出現頻度の低いものをカットする\n",
    "# window: 前後の単語を拾う際の窓の広さを決める\n",
    "# epochs: 機械学習の繰り返し回数(デフォルト:5)十分学習できていないときにこの値を調整する\n",
    "model = word2vec.Word2Vec(word_list,min_count=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00904435,  0.00534277,  0.00375054, -0.00605336,  0.00606624,\n",
       "       -0.00113982,  0.00532705, -0.00198728,  0.00572351,  0.00578795,\n",
       "       -0.00270007, -0.00911711, -0.00086151,  0.0028268 , -0.00730402,\n",
       "       -0.00822396,  0.00099289,  0.00080993, -0.00464603, -0.00557673,\n",
       "        0.00827145,  0.00953451, -0.00814784, -0.00735056,  0.0004159 ,\n",
       "       -0.00356807, -0.00062897, -0.00580837, -0.00767971, -0.0048091 ,\n",
       "        0.00368572,  0.00361012, -0.00872424, -0.00864171, -0.00645147,\n",
       "        0.00244312, -0.00828653,  0.0004232 ,  0.00879883, -0.00906996,\n",
       "       -0.00346835,  0.00891898,  0.00697609, -0.00029563, -0.00428081,\n",
       "       -0.00887511, -0.00466706,  0.00085721,  0.0078073 , -0.00229957,\n",
       "        0.00929993, -0.00791849,  0.00531931,  0.00555262, -0.00503432,\n",
       "        0.00774953, -0.00636481,  0.00402099, -0.00960674, -0.000822  ,\n",
       "       -0.00196953,  0.00656306,  0.00407827, -0.00955887, -0.0024127 ,\n",
       "       -0.00562746, -0.00759491,  0.00170983,  0.0072332 , -0.00611929,\n",
       "        0.00902302,  0.00319916, -0.00697173, -0.00032011,  0.0029974 ,\n",
       "        0.00638828, -0.00026052,  0.00966439, -0.00452588, -0.00887171,\n",
       "       -0.00833754,  0.0047477 , -0.00487187, -0.00876146, -0.00599027,\n",
       "        0.00073023,  0.00869039, -0.00283584,  0.00388219, -0.0004528 ,\n",
       "        0.0098864 ,  0.00488327, -0.00768637, -0.00985738, -0.00331965,\n",
       "        0.00266926,  0.00528502,  0.00755208,  0.00391041,  0.00777833],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 確認\n",
    "model.wv['hand']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNlRCelj9wmU1Jb0NP6q8Cx",
   "include_colab_link": true,
   "name": "Untitled9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
